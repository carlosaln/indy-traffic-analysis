{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38a79db",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31477d8",
   "metadata": {},
   "source": [
    "First, we load torch library (+platform) and verify our installation is good. You should get a Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e732711-30f8-4df2-899a-848777eb4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import platform\n",
    "\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fbaf0",
   "metadata": {},
   "source": [
    "Next, we display the CUDA capabilities of the system. If you have a GPU, you should see the CUDA version and the name of the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f9bf1-e36f-4103-ab93-bc12b522aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA capability: {torch.cuda.get_device_capability(0)}\")\n",
    "else:\n",
    "    print(\n",
    "        \"CUDA is NOT available. Please check your CUDA Toolkit and driver installation.\"\n",
    "    )\n",
    "print(\n",
    "    f\"PyTorch installed from: {torch.backends.cudnn.version.__name__ if torch.cuda.is_available() else 'CPU only'}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26ce33-79fb-4838-9707-a86e3dc6d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9abbc7-3fa1-4112-8805-649437ada01f",
   "metadata": {},
   "source": [
    "## Photo Object Detection Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7798872-5c9f-446f-bc56-88078225012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "image_path = 'https://ultralytics.com/images/bus.jpg'\n",
    "print(f\"Running inference on: {image_path}\")\n",
    "\n",
    "# Time the inference\n",
    "start_time = time.perf_counter()\n",
    "results = model(image_path, verbose=False)\n",
    "inference_time = time.perf_counter() - start_time\n",
    "\n",
    "# Time the visualization and count objects\n",
    "viz_start_time = time.perf_counter()\n",
    "object_counts = Counter()\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Detected {len(r.boxes)} objects\")\n",
    "    \n",
    "    if r.boxes is not None:\n",
    "        for box in r.boxes:\n",
    "            class_id = int(box.cls.item())\n",
    "            class_name = model.names[class_id]\n",
    "            object_counts[class_name] += 1\n",
    "    \n",
    "    annotated_image_array = r.plot()\n",
    "    annotated_image_rgb = cv2.cvtColor(annotated_image_array, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(annotated_image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Detected Objects: {len(r.boxes)}\")\n",
    "    plt.show()\n",
    "viz_time = time.perf_counter() - viz_start_time\n",
    "\n",
    "print(f\"\\n=== PHOTO PROCESSING METRICS ===\")\n",
    "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "print(f\"Visualization time: {viz_time:.4f} seconds\")\n",
    "print(f\"Total time: {inference_time + viz_time:.4f} seconds\")\n",
    "\n",
    "print(f\"\\n=== OBJECT DETECTION COUNTS ===\")\n",
    "if object_counts:\n",
    "    print(\"Objects detected by type:\")\n",
    "    for obj_type, count in sorted(object_counts.items()):\n",
    "        print(f\"  {obj_type}: {count}\")\n",
    "    print(f\"Total objects: {sum(object_counts.values())}\")\n",
    "else:\n",
    "    print(\"No objects detected\")\n",
    "\n",
    "print(\"Basic YOLOv11 test completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642c1d9-7279-4fe8-b369-0c21ed6abc8d",
   "metadata": {},
   "source": [
    "# Video Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94932a6-e5a8-40f0-a473-56e8e336231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "model = YOLO('yolo11n.pt')\n",
    "video_path = os.path.join(os.getcwd(), 'traffic.mp4')  \n",
    "output_path = 'annotated_traffic_output.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video source at {video_path}. Please check the path or webcam availability.\")\n",
    "else:\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\"Processing video from: {video_path}\")\n",
    "    print(f\"Output video: {output_path}\")\n",
    "    print(f\"Video properties: {width}x{height} @ {fps} FPS, {total_frames} frames\")\n",
    "    \n",
    "    frames_to_process = min(100, total_frames) # Process first 100 frames or entire video if shorter\n",
    "    processed_count = 0\n",
    "    \n",
    "    # Initialize timing variables and object counter\n",
    "    total_inference_time = 0\n",
    "    total_write_time = 0\n",
    "    frame_times = []\n",
    "    overall_start_time = time.perf_counter()\n",
    "    video_object_counts = Counter()\n",
    "    \n",
    "    while processed_count < frames_to_process:\n",
    "        frame_start_time = time.perf_counter()\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of video or failed to read frame.\")\n",
    "            break\n",
    "            \n",
    "        # Time the inference for this frame\n",
    "        inference_start = time.perf_counter()\n",
    "        results = model(frame, verbose=False) \n",
    "        inference_time = time.perf_counter() - inference_start\n",
    "        total_inference_time += inference_time\n",
    "        \n",
    "        # Count objects in this frame\n",
    "        if results[0].boxes is not None:\n",
    "            for box in results[0].boxes:\n",
    "                class_id = int(box.cls.item())\n",
    "                class_name = model.names[class_id]\n",
    "                video_object_counts[class_name] += 1\n",
    "        \n",
    "        # Time the video writing\n",
    "        write_start = time.perf_counter()\n",
    "        annotated_frame = results[0].plot() # Get annotated frame as numpy array\n",
    "        out.write(annotated_frame) # Write frame to output video\n",
    "        write_time = time.perf_counter() - write_start\n",
    "        total_write_time += write_time\n",
    "        \n",
    "        frame_total_time = time.perf_counter() - frame_start_time\n",
    "        frame_times.append(frame_total_time)\n",
    "        \n",
    "        processed_count += 1\n",
    "        \n",
    "        # Progress update every 10 frames\n",
    "        if processed_count % 10 == 0:\n",
    "            progress = (processed_count / frames_to_process) * 100\n",
    "        \n",
    "    overall_time = time.perf_counter() - overall_start_time\n",
    "    \n",
    "    # Clean up\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # Check if output file was created successfully\n",
    "    if os.path.exists(output_path):\n",
    "        file_size = os.path.getsize(output_path) / (1024 * 1024)  # Size in MB\n",
    "        print(f\"\\n=== OUTPUT VIDEO CREATED ===\")\n",
    "        print(f\"File: {output_path}\")\n",
    "        print(f\"Size: {file_size:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"\\nWarning: Output file {output_path} was not created successfully.\")\n",
    "    \n",
    "    # Print comprehensive timing metrics\n",
    "    print(f\"\\n=== VIDEO PROCESSING METRICS ===\")\n",
    "    print(f\"Frames processed: {processed_count}\")\n",
    "    print(f\"Total inference time: {total_inference_time:.4f} seconds\")\n",
    "    print(f\"Total video writing time: {total_write_time:.4f} seconds\")\n",
    "    print(f\"Average inference per frame: {total_inference_time/processed_count:.4f} seconds\")\n",
    "    print(f\"Average writing per frame: {total_write_time/processed_count:.4f} seconds\")\n",
    "    print(f\"Average processing per frame: {sum(frame_times)/len(frame_times):.4f} seconds\")\n",
    "    print(f\"Frames per second (processing only): {processed_count/sum(frame_times):.2f} FPS\")\n",
    "    print(f\"Overall time: {overall_time:.4f} seconds\")\n",
    "    \n",
    "    # Print object detection counts\n",
    "    print(f\"\\n=== VIDEO OBJECT DETECTION COUNTS ===\")\n",
    "    if video_object_counts:\n",
    "        print(\"Objects detected by type across all processed frames:\")\n",
    "        for obj_type, count in sorted(video_object_counts.items()):\n",
    "            print(f\"  {obj_type}: {count}\")\n",
    "        print(f\"Total objects detected: {sum(video_object_counts.values())}\")\n",
    "        print(f\"Average objects per frame: {sum(video_object_counts.values())/processed_count:.1f}\")\n",
    "    else:\n",
    "        print(\"No objects detected in any frames\")\n",
    "    \n",
    "    print(f\"Output video created: {output_path}\")\n",
    "    print(\"Video processing and export completed.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a06b346f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Complete Video Processing (Full Length)\n",
    "\n",
    "Use this cell to process the entire video file and create a complete annotated output video. This version processes all frames in the video rather than just a sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad83728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Process entire video (uncomment and run this cell for full video processing)\n",
    "model = YOLO('yolo11n.pt')\n",
    "video_path = '/home/calem/traffic.mp4' # change this to your video file location...\n",
    "output_path = 'complete_annotated_traffic.mp4' # Output video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video source at {video_path}. Please check the path or webcam availability.\")\n",
    "else:\n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    # Set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\"Processing COMPLETE video from: {video_path}\")\n",
    "    print(f\"Output video: {output_path}\")\n",
    "    print(f\"Video properties: {width}x{height} @ {fps} FPS\")\n",
    "    print(f\"Total frames: {total_frames} ({duration:.1f} seconds)\")\n",
    "    print(\"This may take several minutes depending on video length and GPU performance...\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    \n",
    "    # Initialize timing variables and object counter\n",
    "    total_inference_time = 0\n",
    "    total_write_time = 0\n",
    "    frame_times = []\n",
    "    overall_start_time = time.perf_counter()\n",
    "    complete_video_object_counts = Counter()\n",
    "    \n",
    "    # Process all frames\n",
    "    while True:\n",
    "        frame_start_time = time.perf_counter()\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Reached end of video.\")\n",
    "            break\n",
    "            \n",
    "        # Time the inference for this frame\n",
    "        inference_start = time.perf_counter()\n",
    "        results = model(frame, verbose=False) \n",
    "        inference_time = time.perf_counter() - inference_start\n",
    "        total_inference_time += inference_time\n",
    "        \n",
    "        # Count objects in this frame\n",
    "        if results[0].boxes is not None:\n",
    "            for box in results[0].boxes:\n",
    "                class_id = int(box.cls.item())\n",
    "                class_name = model.names[class_id]\n",
    "                complete_video_object_counts[class_name] += 1\n",
    "        \n",
    "        # Time the video writing\n",
    "        write_start = time.perf_counter()\n",
    "        annotated_frame = results[0].plot() # Get annotated frame as numpy array\n",
    "        out.write(annotated_frame) # Write frame to output video\n",
    "        write_time = time.perf_counter() - write_start\n",
    "        total_write_time += write_time\n",
    "        \n",
    "        frame_total_time = time.perf_counter() - frame_start_time\n",
    "        frame_times.append(frame_total_time)\n",
    "        \n",
    "        processed_count += 1\n",
    "        \n",
    "        # Progress update every 50 frames to avoid spam\n",
    "        if processed_count % 50 == 0:\n",
    "            progress = (processed_count / total_frames) * 100\n",
    "            elapsed_time = time.perf_counter() - overall_start_time\n",
    "            estimated_total = elapsed_time * (total_frames / processed_count)\n",
    "            remaining_time = estimated_total - elapsed_time\n",
    "        \n",
    "    overall_time = time.perf_counter() - overall_start_time\n",
    "    \n",
    "    # Clean up\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # Check if output file was created successfully\n",
    "    if os.path.exists(output_path):\n",
    "        file_size = os.path.getsize(output_path) / (1024 * 1024)  # Size in MB\n",
    "        print(f\"\\n=== COMPLETE OUTPUT VIDEO CREATED ===\")\n",
    "        print(f\"File: {output_path}\")\n",
    "        print(f\"Size: {file_size:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"\\nWarning: Output file {output_path} was not created successfully.\")\n",
    "    \n",
    "    # Print comprehensive timing metrics\n",
    "    print(f\"\\n=== COMPLETE VIDEO PROCESSING METRICS ===\")\n",
    "    print(f\"Frames processed: {processed_count}\")\n",
    "    print(f\"Original video duration: {duration:.1f} seconds\")\n",
    "    print(f\"Processing time: {overall_time/60:.1f} minutes\")\n",
    "    print(f\"Processing speed: {overall_time/duration:.1f}x real-time\")\n",
    "    print(f\"Total inference time: {total_inference_time:.4f} seconds\")\n",
    "    print(f\"Total video writing time: {total_write_time:.4f} seconds\")\n",
    "    print(f\"Average inference per frame: {total_inference_time/processed_count:.4f} seconds\")\n",
    "    print(f\"Average writing per frame: {total_write_time/processed_count:.4f} seconds\")\n",
    "    print(f\"Average processing per frame: {sum(frame_times)/len(frame_times):.4f} seconds\")\n",
    "    print(f\"Theoretical max FPS: {1/(total_inference_time/processed_count):.1f} FPS\")\n",
    "    print(f\"Actual processing FPS: {processed_count/sum(frame_times):.2f} FPS\")\n",
    "    \n",
    "    # Print complete video object detection counts\n",
    "    print(f\"\\n=== COMPLETE VIDEO OBJECT DETECTION COUNTS ===\")\n",
    "    if complete_video_object_counts:\n",
    "        print(\"Objects detected by type across entire video:\")\n",
    "        for obj_type, count in sorted(complete_video_object_counts.items()):\n",
    "            print(f\"  {obj_type}: {count}\")\n",
    "        print(f\"Total objects detected: {sum(complete_video_object_counts.values())}\")\n",
    "        print(f\"Average objects per frame: {sum(complete_video_object_counts.values())/processed_count:.1f}\")\n",
    "        print(f\"Objects per second: {sum(complete_video_object_counts.values())/duration:.1f}\")\n",
    "    else:\n",
    "        print(\"No objects detected in any frames\")\n",
    "    \n",
    "    print(f\"Complete annotated video saved as: {output_path}\")\n",
    "    print(\"Complete video processing finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb5581-fa43-423c-b156-708333db1a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
